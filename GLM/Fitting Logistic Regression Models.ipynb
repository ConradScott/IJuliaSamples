{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\cond}{{\\mkern+2mu} \\vert {\\mkern+2mu}}\n",
    "\\newcommand{\\SetDiff}{\\mathrel{\\backslash}}\n",
    "\\DeclareMathOperator{\\BetaFunc}{Β}\n",
    "\\DeclareMathOperator{\\GammaFunc}{Γ}\n",
    "\\DeclareMathOperator{\\prob}{p}\n",
    "\\DeclareMathOperator{\\cost}{J}\n",
    "\\DeclareMathOperator{\\score}{V}\n",
    "\\DeclareMathOperator{\\dcategorical}{Categorical}\n",
    "\\DeclareMathOperator{\\dcategorical}{Categorical}\n",
    "\\DeclareMathOperator{\\ddirichlet}{Dirichlet}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"The logistic regression model arises from the desire to model the posterior probabilities of the $K$ classes via linear functions in $x$, while at the same time ensuring that they sum to one and remain in $[0, 1]$.\", Hastie et al., 2009 (p. 119)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\log \\frac{\\prob(Y = k \\cond X = x)}{\\prob(Y = K \\cond X = x)} = \\beta_k^{\\text{T}} x && \\text{for } k = 1, \\dotsc, K-1.\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability for the case $Y = K$ is held out, as the probabilities must sum to one, so there are only $K-1$ free variables.\n",
    "Thus if there are two categories, there is just a single linear function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us that\n",
    "$$\n",
    "\\begin{align}\n",
    "\\prob(Y = k \\cond X = x) &= \\frac{\\exp(\\beta_k^{\\text{T}}x)}{1 + \\sum_{i=1}^{K-1} \\exp(\\beta_i^{\\text{T}}x)} & \\text{for } k = 1, \\dotsc, K-1 \\\\[3pt]\n",
    "\\prob(Y = K \\cond X = x) &= \\frac{1}{1 + \\sum_{i=1}^{K-1} \\exp(\\beta_i^{\\text{T}}x)}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note that if we fix $\\beta_K = 0$, we have the form\n",
    "$$\n",
    "\\begin{align}\n",
    "\\prob(Y = k \\cond X = x) &= \\frac{\\exp(\\beta_k^{\\text{T}}x)}{\\sum_{i=1}^K \\exp(\\beta_i^{\\text{T}}x)} & \\text{for } k = 1, \\dotsc, K.\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, writing $\\beta = \\{\\beta_1^{\\text{T}}, \\dotsc, \\beta_{K-1}^{\\text{T}}\\}$, we have that $\\prob(Y = k \\cond X = x) = \\prob_k(x; \\beta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log likelihood for $N$ observations is\n",
    "$$\n",
    "\\ell(\\beta) = \\sum_{n=1}^N \\log \\prob_{y_n}(x_n; \\beta).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the cost function\n",
    "$$\n",
    "\\begin{align}\n",
    "\\cost(\\beta)\n",
    "    &= -\\frac{1}{N} \\left[ \\sum_{n=1}^N \\sum_{k=1}^K 1[y_n = k] \\log \\prob_k(x_n; \\beta) \\right] \\\\\n",
    "    &= -\\frac{1}{N} \\left[ \\sum_{n=1}^N \\sum_{k=1}^K 1[y_n = k] \\log \\frac{\\exp(\\beta_k^{\\text{T}}x_n)}{\\sum_{i=1}^K \\exp(\\beta_i^{\\text{T}}x_n)} \\right] \\\\\n",
    "    &= -\\frac{1}{N} \\left[ \\sum_{n=1}^N \\sum_{k=1}^K 1[y_n = k] \\left( \\beta_k^{\\text{T}}x_n - \\log \\sum_{i=1}^K \\exp(\\beta_i^{\\text{T}}x_n) \\right) \\right].\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the score function is\n",
    "$$\n",
    "\\score_k(\\beta) = \\nabla_{\\beta_k} \\cost(\\beta) = -\\frac{1}{N} \\left[ \\sum_{n=1}^N x_n \\big( 1[y_n = k] - \\prob_k(x_n; \\beta) \\big) \\right].\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.3-pre",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
